---
# Silence for NodeMemoryHighUtilization on NAS host
# This is kept because the alert comes from VictoriaMetrics defaultRules and requires
# label-based filtering (instance-specific) that's difficult to replicate in custom rules
apiVersion: observability.giantswarm.io/v1alpha2
kind: Silence
metadata:
  name: node-memory-high-utilization
  namespace: monitoring
spec:
  matchers:
    - name: alertname
      value: NodeMemoryHighUtilization
    - name: instance
      value: nas.home:9100
---
# COMMENTED OUT - No longer needed
# HostOutOfMemory alert now excludes nas.home:9100 directly in prometheus-rules/node-exporter.yaml
# See: kubernetes/monitoring/prometheus-rules/node-exporter.yaml:16
# ---
# apiVersion: observability.giantswarm.io/v1alpha2
# kind: Silence
# metadata:
#   name: nas-out-of-memory
#   namespace: monitoring
# spec:
#   matchers:
#     - name: alertname
#       value: HostOutOfMemory
#     - name: instance
#       value: nas.home:9100
---
# COMMENTED OUT - No longer needed
# HostSwapIsFillingUp alert now excludes nas.home:9100 directly in prometheus-rules/node-exporter.yaml
# See: kubernetes/monitoring/prometheus-rules/node-exporter.yaml:96
# ---
# apiVersion: observability.giantswarm.io/v1alpha2
# kind: Silence
# metadata:
#   name: nas-host-swap-is-filling-up
#   namespace: monitoring
# spec:
#   matchers:
#     - name: alertname
#       value: HostSwapIsFillingUp
#     - name: instance
#       value: nas.home:9100
---
# COMMENTED OUT - No longer needed
# HostNodeOvertemperatureAlarm alert now excludes 10.0.7.55:9100 directly in prometheus-rules/node-exporter.yaml
# See: kubernetes/monitoring/prometheus-rules/node-exporter.yaml:120
# ---
# apiVersion: observability.giantswarm.io/v1alpha2
# kind: Silence
# metadata:
#   name: host-node-overtemperature-alarm
#   namespace: monitoring
# spec:
#   matchers:
#     - name: alertname
#       value: HostNodeOvertemperatureAlarm
#     - name: instance
#       value: 10.0.7.55:9100
---
# COMMENTED OUT - No longer needed
# HostPhysicalComponentTooHot alert now excludes these instances directly in prometheus-rules/node-exporter.yaml
# See: kubernetes/monitoring/prometheus-rules/node-exporter.yaml:112
# ---
# apiVersion: observability.giantswarm.io/v1alpha2
# kind: Silence
# metadata:
#   name: host-physical-component-too-hot
#   namespace: monitoring
# spec:
#   matchers:
#     - name: alertname
#       value: HostPhysicalComponentTooHot
#     - name: instance
#       value: 10\.0\.7\.(52|55|59):9100
#       matchType: "=~"
---
# Silence for CephPGImbalance on osd.4
# This is kept because osd.4 is a smaller drive (894 GiB vs 1.7 TiB) so PG imbalance is expected.
# The alert comes from rook-ceph rules and requires label-based filtering (ceph_daemon-specific)
# that's difficult to replicate without recreating the complex Ceph rules.
apiVersion: observability.giantswarm.io/v1alpha2
kind: Silence
metadata:
  name: ceph-pg-imbalance
  namespace: monitoring
spec:
  matchers:
    - name: alertname
      value: CephPGImbalance
    - name: ceph_daemon
      value: osd.4
      matchType: "=~"
