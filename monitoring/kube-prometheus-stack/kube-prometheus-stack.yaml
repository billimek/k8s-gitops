---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://prometheus-community.github.io/helm-charts
      chart: kube-prometheus-stack
      version: 12.9.2
      sourceRef:
        kind: HelmRepository
        name: prometheus-community-charts
        namespace: flux-system
      interval: 5m
  timeout: 20m
  values:
    # defaultRules:
    #   rules:
    #     kubeApiserverAvailability: true
    #     kubeApiserver: true
    server:
      resources:
        requests:
          memory: 1500Mi
          cpu: 25m
        limits:
          memory: 2000Mi
    prometheusOperator:
      createCustomResource: true
      # prometheusConfigReloaderImage:
      #   repository: quay.io/coreos/prometheus-config-reloader
      #   tag: v0.39.0
      # configmapReloadImage:
      #   repository: jimmidyson/configmap-reload
      #   tag: v0.4.0
    alertmanager:
      alertmanagerSpec:
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: rook-ceph-block
              resources:
                requests:
                  storage: 10Gi
        tolerations:
        - key: "arm"
          operator: "Exists"
        podMetadata:
          annotations:
            backup.velero.io/backup-volumes: alertmanager-kube-prometheus-stack-alertmanager-db
      ingress:
        enabled: true
        annotations:
          kubernetes.io/ingress.class: "nginx"
          nginx.ingress.kubernetes.io/auth-url: "https://auth.eviljungle.com/oauth2/auth"
          nginx.ingress.kubernetes.io/auth-signin: https://auth.eviljungle.com/oauth2/start
        hosts: [prom-alert.eviljungle.com]
        tls:
        - hosts:
          - prom-alert.eviljungle.com
      config:
        global:
          resolve_timeout: 5m
        route:
          # group_by: ['alertname', 'job']
          # group_wait: 30s
          # group_interval: 5m
          # repeat_interval: 6h
          receiver: 'slack-notifications'
          # receiver: 'pagerduty'
          routes:
            - match:
                alertname: Watchdog
              receiver: 'null'
            - receiver: 'pagerduty'
              match:
                severity: critical
              continue: true
            - receiver: 'slack-notifications'
        inhibit_rules:
        - source_match:
            severity: 'critical'
          target_match:
            severity: 'warning'
          # Apply inhibition if the alertname is the same.
          equal: ['alertname', 'namespace']
        templates: ["*.tmpl"]
      templateFiles:
        pagerduty-custom.tmpl: |-
          {{- define "pagerduty.custom.description" -}}[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ if ne .CommonAnnotations.summary ""}}{{ .CommonAnnotations.summary }} {{ else if ne .CommonAnnotations.message ""}}{{ .CommonAnnotations.message }} {{ else if ne .CommonAnnotations.description ""}}{{ .CommonAnnotations.description }} {{ else }}{{ .CommonLabels.alertname }}{{ end }}{{- end -}}
    nodeExporter:
      serviceMonitor:
        relabelings:
        - action: replace
          regex: (.*)
          replacement: $1
          sourceLabels:
          - __meta_kubernetes_pod_node_name
          targetLabel: kubernetes_node
    kubelet:
      serviceMonitor:
        metricRelabelings:
        - action: replace
          sourceLabels:
          - node
          targetLabel: instance
    grafana:
      # image:
      #   repository: grafana/grafana
      #   tag: 7.0.4
      # tolerations:
      # - key: "arm"
      #   operator: "Exists"
      deploymentStrategy:
        type: Recreate
      podAnnotations:
        backup.velero.io/backup-volumes: storage
      persistence:
        enabled: true
        storageClassName: "rook-ceph-block"
        size: 10Gi
        accessModes:
        - ReadWriteOnce
      env:
        GF_EXPLORE_ENABLED: true
        GF_DISABLE_SANITIZE_HTML: true
        GF_PANELS_DISABLE_SANITIZE_HTML: true
        VAR_BLOCKY_URL: "http://blocky.default.svc.cluster.local:4000"
      ingress:
        enabled: true
        annotations:
          kubernetes.io/ingress.class: "nginx"
        hosts: [grafana.eviljungle.com]
        tls:
        - hosts:
          - grafana.eviljungle.com
      plugins:
      - natel-discrete-panel
      - pr0ps-trackmap-panel
      - grafana-piechart-panel
      - grafana-clock-panel
      - https://github.com/panodata/grafana-map-panel/releases/download/0.9.0/grafana-map-panel-0.9.0.zip;grafana-worldmap-panel-ng
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
          - name: 'default'
            orgId: 1
            folder: ''
            type: file
            disableDeletion: false
            editable: true
            options:
              path: /var/lib/grafana/dashboards/default
          - name: 'teslamate'
            orgId: 1
            folder: Teslamate
            # folderUid: Nr4ofiDZk
            type: file
            disableDeletion: false
            editable: true
            # updateIntervalSeconds: -1
            allowUiUpdates: true
            options:
              path: /var/lib/grafana/dashboards/teslamate
      dashboards:
        default:
          flux-cluster:
            url: https://raw.githubusercontent.com/fluxcd/flux2/v0.4.2/manifests/monitoring/grafana/dashboards/cluster.json
            datasource: Prometheus
          flux-control-plane:
            url: https://raw.githubusercontent.com/fluxcd/flux2/v0.4.2/manifests/monitoring/grafana/dashboards/control-plane.json
            datasource: Prometheus
          nginx-dashboard:
            url: https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/grafana/dashboards/nginx.json
            datasource: Prometheus
          ceph-cluster:
            url: https://grafana.com/api/dashboards/2842/revisions/11/download
            datasource: Prometheus
          ceph-osd:
            url: https://grafana.com/api/dashboards/5336/revisions/3/download
            datasource: Prometheus
          ceph-pools:
            url: https://grafana.com/api/dashboards/5342/revisions/3/download
            datasource: Prometheus
          vernemq:
            url: https://raw.githubusercontent.com/vernemq/vernemq/master/metrics_scripts/grafana/VerneMQ%20Node%20Metrics.json
            datasource: Prometheus
          velero:
            url: https://grafana.com/api/dashboards/11055/revisions/2/download
            datasource: Prometheus
          blocky:
            url: https://raw.githubusercontent.com/0xERR0R/blocky/v0.11/docs/blocky-grafana.json
            datasource: Prometheus
          uptimerobot:
            url: https://raw.githubusercontent.com/lekpamartin/uptimerobot_exporter/master/dashboards/grafana.json
            datasource: Prometheus
          1-node-exporter:
            url: https://grafana.com/api/dashboards/11074/revisions/9/download
            datasource: Prometheus 
          TrueNAS:
            url: https://grafana.com/api/dashboards/12921/revisions/1/download
            datasource: TrueNAS
          # cable-modem-stats:
          #   url: https://raw.githubusercontent.com/billimek/k8s-gitops/master/monitoring/prometheus-operator/grafana-dashboards/cable_modem_stats.json
          #   datasource: influxdb
          # comcast-sucks:
          #   url: https://raw.githubusercontent.com/billimek/k8s-gitops/master/monitoring/prometheus-operator/grafana-dashboards/comcast_sucks.json
          #   datasource: influxdb
          # home-assistant:
          #   url: https://raw.githubusercontent.com/billimek/k8s-gitops/master/monitoring/prometheus-operator/grafana-dashboards/home_assistant.json
          #   datasource: influxdb
          # ups:
          #   url: https://raw.githubusercontent.com/billimek/k8s-gitops/master/monitoring/prometheus-operator/grafana-dashboards/ups.json
          #   datasource: influxdb
          # netdata:
          #   url: https://raw.githubusercontent.com/billimek/k8s-gitops/master/monitoring/prometheus-operator/grafana-dashboards/netdata.json
          #   datasource: Prometheus
        teslamate:
          charge-level:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/charge-level.json
            # datasource: TeslaMate
          charges:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/charges.json
            # datasource: TeslaMate
          charging-stats:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/charging-stats.json
            # datasource: TeslaMate
          drive-stats:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/drive-stats.json
            # datasource: TeslaMate
          drives:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/drives.json
            # datasource: TeslaMate
          efficiency:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/efficiency.json
            # datasource: TeslaMate
          locations:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/locations.json
            # datasource: TeslaMate
          mileage:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/mileage.json
            # datasource: TeslaMate
          overview:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/overview.json
            # datasource: TeslaMate
          projected-range:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/projected-range.json
            # datasource: TeslaMate
          states:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/states.json
            # datasource: TeslaMate
          trip:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/trip.json
            # datasource: TeslaMate
          updates:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/updates.json
            # datasource: TeslaMate
          vampire-drain:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/vampire-drain.json
            # datasource: TeslaMate
          visited:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/visited.json
            # datasource: TeslaMate
          charge-details:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/internal/charge-details.json
          drive-details:
            url: https://raw.githubusercontent.com/adriankumpf/teslamate/v1.20.1/grafana/dashboards/internal/drive-details.json
      sidecar:
        datasources:
          enabled: true
          defaultDatasourceEnabled: false
        dashboards:
          enabled: true
          searchNamespace: ALL
      additionalDataSources:
      - name: Prometheus
        type: prometheus
        access: proxy
        url: http://thanos-query-http:10902/
        isDefault: true
      - name: loki
        type: loki
        access: proxy
        url: http://loki.logs.svc.cluster.local:3100
      - name: influxdb
        type: influxdb
        access: proxy
        url: http://influxdb:8086
        database: telegraf
      - name: cable_modem_stats
        type: influxdb
        access: proxy
        url: http://influxdb:8086
        database: cable_modem_stats
      - name: comcast
        type: influxdb
        access: proxy
        url: http://influxdb:8086
        database: comcast
      - name: home_assistant
        type: influxdb
        access: proxy
        url: http://influxdb:8086
        database: home_assistant
      - name: speedtests
        type: influxdb
        access: proxy
        url: http://influxdb:8086
        database: speedtests
      - name: uptimerobot
        type: influxdb
        access: proxy
        url: http://influxdb:8086
        database: uptimerobot
      - name: TrueNAS
        type: influxdb
        access: proxy
        url: http://influxdb:8086
        database: graphitedb
      grafana.ini:
        paths:
          data: /var/lib/grafana/data
          logs: /var/log/grafana
          plugins: /var/lib/grafana/plugins
          provisioning: /etc/grafana/provisioning
        analytics:
          check_for_updates: true
        log:
          mode: console
        grafana_net:
          url: https://grafana.net
    kubeEtcd:
      enabled: false
    kubeControllerManager:
      enabled: false
      # endpoints:
      # - 10.2.0.30
    kubeScheduler:
      enabled: false
      # endpoints:
      # - 10.2.0.30
    kubeProxy:
      enabled: false
    prometheus-node-exporter:
      tolerations:
      - key: "arm"
        operator: "Exists"
      - key: "armhf"
        operator: "Exists"
      - key: "node-role.kubernetes.io/master"
        operator: "Exists"
    prometheus:
      ingress:
        enabled: true
        annotations:
          kubernetes.io/ingress.class: "nginx"
          nginx.ingress.kubernetes.io/auth-url: "https://auth.eviljungle.com/oauth2/auth"
          nginx.ingress.kubernetes.io/auth-signin: https://auth.eviljungle.com/oauth2/start
        hosts: [prom-server.eviljungle.com]
        tls:
        - hosts:
          - prom-server.eviljungle.com
      prometheusSpec:
        # image:
        #   repository: quay.io/prometheus/prometheus
        #   tag: v2.20.0
        replicas: 2
        replicaExternalLabelName: "replica"
        ruleSelector: {}
        ruleNamespaceSelector: {}
        ruleSelectorNilUsesHelmValues: false
        serviceMonitorSelector: {}
        serviceMonitorNamespaceSelector: {}
        serviceMonitorSelectorNilUsesHelmValues: false
        podMonitorSelector: {}
        podMonitorNamespaceSelector: {}
        podMonitorSelectorNilUsesHelmValues: false
        retention: 6h
        enableAdminAPI: true
        walCompression: true
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: rook-ceph-block
              resources:
                requests:
                  storage: 10Gi
        # tolerations:
        # - key: "arm"
        #   operator: "Exists"
        podMetadata:
          annotations:
            backup.velero.io/backup-volumes: prometheus-kube-prometheus-stack-prometheus-db
        thanos:
          image: quay.io/thanos/thanos:v0.15.0
          version: v0.15.0
          objectStorageConfig:
            name: thanos
            key: object-store.yaml
  valuesFrom:
  - kind: Secret
    name: "kube-prometheus-stack-helm-values"
    optional: false
